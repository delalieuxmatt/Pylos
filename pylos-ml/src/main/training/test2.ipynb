{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.718441Z",
     "start_time": "2025-11-13T20:19:00.714719Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATASET_PATH = \"resources/games/all_battles.json\"\n",
    "MODEL_EXPORT_PATH = \"resources/models/\"\n",
    "SELECTED_PLAYERS = []\n",
    "DISCOUNT_FACTOR = 0.98\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 512\n",
    "N_CORES = 8\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(N_CORES)\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = str(N_CORES)\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = str(N_CORES)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "d4564bd3b270bd61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.726178Z",
     "start_time": "2025-11-13T20:19:00.724147Z"
    }
   },
   "source": [
    "#cuda fouten verbergen\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "802c5f6995fe432e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.777625Z",
     "start_time": "2025-11-13T20:19:00.773456Z"
    }
   },
   "source": [
    "def build_dataset(path):\n",
    "    \"\"\"\n",
    "    CRITICAL FIX: Generate training data from BOTH players' perspectives.\n",
    "\n",
    "    The key insight: In a two-player zero-sum game, we need to train the model\n",
    "    to evaluate positions from a consistent perspective. We do this by:\n",
    "    1. For each board position, create TWO training examples\n",
    "    2. One from Light's perspective (original board, positive if Light wins)\n",
    "    3. One from Dark's perspective (inverted board, positive if Dark wins)\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"Processing {len(data)} games\")\n",
    "\n",
    "    boards = []\n",
    "    scores = []\n",
    "\n",
    "    for game_idx, game in enumerate(data):\n",
    "        # Skip games that don't have both players in the selected players list\n",
    "        if SELECTED_PLAYERS and (\n",
    "                game[\"lightPlayer\"] not in SELECTED_PLAYERS or\n",
    "                game[\"darkPlayer\"] not in SELECTED_PLAYERS\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        winner = game[\"winner\"]  # 1 for Light, -1 for Dark\n",
    "        n_moves = len(game[\"boardHistory\"])\n",
    "        reserve_size = game['reserveSize']\n",
    "\n",
    "        for i, board_as_long in enumerate(game[\"boardHistory\"]):\n",
    "            # Convert board to array (0 = Light, 1 = Dark)\n",
    "            board_as_array = np.array(\n",
    "                [(board_as_long >> j) & 1 for j in range(59, -1, -1)],\n",
    "                dtype=np.float32\n",
    "            )\n",
    "\n",
    "            # Calculate discount based on proximity to end of game\n",
    "            # Positions closer to the end are more certain\n",
    "            discount = DISCOUNT_FACTOR ** (n_moves - i - 1)\n",
    "\n",
    "            # Light's perspective: positive if Light wins\n",
    "            light_score = winner * discount * reserve_size\n",
    "            boards.append(board_as_array)\n",
    "            scores.append(light_score)\n",
    "\n",
    "            # Dark's perspective: flip the board (0->1, 1->0) and score\n",
    "            # This teaches the model to evaluate from the active player's view\n",
    "            dark_board = 1.0 - board_as_array\n",
    "            dark_score = -winner * discount * reserve_size  # Flip the score\n",
    "            boards.append(dark_board)\n",
    "            scores.append(dark_score)\n",
    "\n",
    "        if game_idx % 1000 == 0:\n",
    "            print(f\"Processed game {game_idx}/{len(data)}\")\n",
    "\n",
    "    boards_array = np.array(boards, dtype=np.float32)\n",
    "    scores_array = np.array(scores, dtype=np.float32)\n",
    "\n",
    "    # Shuffle the dataset to mix Light and Dark perspectives\n",
    "    indices = np.random.permutation(len(boards_array))\n",
    "\n",
    "    return boards_array[indices], scores_array[indices]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "21898dfd78f9b72f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.827008Z",
     "start_time": "2025-11-13T20:19:00.821282Z"
    }
   },
   "source": [
    "def build_conv1d_model(\n",
    "        filters1=32,\n",
    "        filters2=64,\n",
    "        kernel_size=3,\n",
    "        dense_units1=64,\n",
    "        dense_units2=32,\n",
    "        dropout=0.3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Conv1D-model dat de 60 velden als sequentie ziet: (60, 1)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(60,), dtype=tf.float32)\n",
    "\n",
    "    x = layers.Reshape((60, 1))(inputs)  # (batch, 60, 1)\n",
    "\n",
    "    x = layers.Conv1D(filters1, kernel_size=kernel_size,\n",
    "                      activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv1D(filters2, kernel_size=kernel_size,\n",
    "                      activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(dense_units1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    x = layers.Dense(dense_units2, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_conv2d_model(\n",
    "        filters1,\n",
    "        filters2,\n",
    "        kernel_size,\n",
    "        dense_units1,\n",
    "        dense_units2,\n",
    "        dropout,\n",
    "):\n",
    "    \"\"\"\n",
    "    Conv2D-model: we reshapen 60 -> (6, 10, 1).\n",
    "    Dit is een beetje artificieel, maar laat je 2D-convs testen.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(60,), dtype=tf.float32)\n",
    "\n",
    "    x = layers.Reshape((6, 10, 1))(inputs)  # (batch, 6, 10, 1)\n",
    "\n",
    "    x = layers.Conv2D(filters1, kernel_size=kernel_size,\n",
    "                      activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size=kernel_size,\n",
    "                      activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(dense_units1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    x = layers.Dense(dense_units2, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "7c853514ff940ecb",
   "metadata": {},
   "source": [
    "Dense modellen"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0b8f3d83e47f2fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.880221Z",
     "start_time": "2025-11-13T20:19:00.873320Z"
    }
   },
   "source": [
    "def build_dense4_model(\n",
    "        units1=256,\n",
    "        units2=128,\n",
    "        units3=64,\n",
    "        units4=32,\n",
    "        dropout1=0.3,\n",
    "        dropout2=0.3,\n",
    "        dropout3=0.2,\n",
    "):\n",
    "\n",
    "    inputs = layers.Input(shape=(60,), dtype=tf.float32)\n",
    "\n",
    "    x = layers.Dense(units1, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout1)(x)\n",
    "\n",
    "    x = layers.Dense(units2, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout2)(x)\n",
    "\n",
    "    x = layers.Dense(units3, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout3)(x)\n",
    "\n",
    "    x = layers.Dense(units4, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_dense5_model(\n",
    "        units1=256,\n",
    "        units2=192,\n",
    "        units3=128,\n",
    "        units4=64,\n",
    "        units5=32,\n",
    "        dropout1=0.3,\n",
    "        dropout2=0.3,\n",
    "        dropout3=0.2,\n",
    "        dropout4=0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    5-laags MLP voor als je echt diep wilt gaan.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(60,), dtype=tf.float32)\n",
    "\n",
    "    x = layers.Dense(units1, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout1)(x)\n",
    "\n",
    "    x = layers.Dense(units2, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout2)(x)\n",
    "\n",
    "    x = layers.Dense(units3, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout3)(x)\n",
    "\n",
    "    x = layers.Dense(units4, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout4)(x)\n",
    "\n",
    "    x = layers.Dense(units5, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "def build_dense6_model(\n",
    "        units1=384, units2=256, units3=192, units4=128, units5=64, units6=32,\n",
    "        dropout1=0.3, dropout2=0.3, dropout3=0.3, dropout4=0.2, dropout5=0.2,\n",
    "):\n",
    "    inputs = layers.Input(shape=(60,), dtype=tf.float32)\n",
    "\n",
    "    x = layers.Dense(units1, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout1)(x)\n",
    "\n",
    "    x = layers.Dense(units2, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout2)(x)\n",
    "\n",
    "    x = layers.Dense(units3, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout3)(x)\n",
    "\n",
    "    x = layers.Dense(units4, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout4)(x)\n",
    "\n",
    "    x = layers.Dense(units5, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout5)(x)\n",
    "\n",
    "    x = layers.Dense(units6, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "c41010690df3d434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.929535Z",
     "start_time": "2025-11-13T20:19:00.925507Z"
    }
   },
   "source": [
    "def create_optimizer(name, learning_rate):\n",
    "    name = name.lower()\n",
    "    if name == \"adam\":\n",
    "        return tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif name == \"sgd\":\n",
    "        return tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    elif name == \"rmsprop\":\n",
    "        return tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer name: {name}\")\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "d7e48a3fd765e3e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:00.978045Z",
     "start_time": "2025-11-13T20:19:00.973847Z"
    }
   },
   "source": [
    "def train_single_experiment(\n",
    "        model_builder,\n",
    "        model_kwargs,\n",
    "        optimizer_name,\n",
    "        learning_rate,\n",
    "        batch_size,\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        X_test, y_test,\n",
    "        label,\n",
    "        family,\n",
    "):\n",
    "    print(f\"\\n==== Running experiment: {label} ({family}) ====\")\n",
    "\n",
    "    model = model_builder(**model_kwargs)\n",
    "    opt = create_optimizer(optimizer_name, learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=4,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    best_val_loss = float(min(history.history[\"val_loss\"]))\n",
    "    best_val_mae = float(min(history.history[\"val_mae\"]))\n",
    "\n",
    "    print(f\"Best val_loss: {best_val_loss:.4f}, best val_mae: {best_val_mae:.4f}\")\n",
    "    print(f\"Test loss:     {test_loss:.4f}, test MAE:     {test_mae:.4f}\")\n",
    "\n",
    "    result = {\n",
    "        \"label\": label,\n",
    "        \"family\": family,\n",
    "        \"optimizer\": optimizer_name,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"best_val_mae\": best_val_mae,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"history\": history.history,\n",
    "    }\n",
    "    return result\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "7fd941273fe18dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:01.030494Z",
     "start_time": "2025-11-13T20:19:01.021865Z"
    }
   },
   "source": [
    "def generate_experiments():\n",
    "    experiments = []\n",
    "\n",
    "    conv1d_archs = [\n",
    "        {\n",
    "            \"name\": \"conv1d_small\",\n",
    "            \"family\": \"conv1d\",\n",
    "            \"builder\": build_conv1d_model,\n",
    "            \"kwargs\": dict(\n",
    "                filters1=32, filters2=64,\n",
    "                kernel_size=3,\n",
    "                dense_units1=64, dense_units2=32,\n",
    "                dropout=0.3,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"conv1d_medium\",\n",
    "            \"family\": \"conv1d\",\n",
    "            \"builder\": build_conv1d_model,\n",
    "            \"kwargs\": dict(\n",
    "                filters1=64, filters2=128,\n",
    "                kernel_size=5,\n",
    "                dense_units1=128, dense_units2=64,\n",
    "                dropout=0.4,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"conv1d_large\",\n",
    "            \"family\": \"conv1d\",\n",
    "            \"builder\": build_conv1d_model,\n",
    "            \"kwargs\": dict(\n",
    "                filters1=96, filters2=192,\n",
    "                kernel_size=5,\n",
    "                dense_units1=128, dense_units2=64,\n",
    "                dropout=0.4,\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    conv_optimizers = [\"adam\", \"rmsprop\", \"sgd\"]\n",
    "    conv_lrs = [0.0005, 0.001]\n",
    "    conv_batch_sizes = [256, 512]\n",
    "\n",
    "    for arch in conv1d_archs:\n",
    "        for opt in conv_optimizers:\n",
    "            for lr in conv_lrs:\n",
    "                for bs in conv_batch_sizes:\n",
    "                    label = f\"{arch['name']}_{opt}_lr{lr}_bs{bs}\"\n",
    "                    experiments.append({\n",
    "                        \"label\": label,\n",
    "                        \"family\": arch[\"family\"],\n",
    "                        \"model_builder\": arch[\"builder\"],\n",
    "                        \"model_kwargs\": arch[\"kwargs\"],\n",
    "                        \"optimizer\": opt,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"batch_size\": bs,\n",
    "                    })\n",
    "\n",
    "    \n",
    "    conv2d_archs = [\n",
    "        {\n",
    "            \"name\": \"conv2d_small\",\n",
    "            \"family\": \"conv2d\",\n",
    "            \"builder\": build_conv2d_model,\n",
    "            \"kwargs\": dict(\n",
    "                filters1=32, filters2=64,\n",
    "                kernel_size=(3, 3),\n",
    "                dense_units1=64, dense_units2=32,\n",
    "                dropout=0.3,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"conv2d_medium\",\n",
    "            \"family\": \"conv2d\",\n",
    "            \"builder\": build_conv2d_model,\n",
    "            \"kwargs\": dict(\n",
    "                filters1=64, filters2=128,\n",
    "                kernel_size=(3, 3),\n",
    "                dense_units1=128, dense_units2=64,\n",
    "                dropout=0.3,\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    conv2_optimizers = [\"adam\", \"rmsprop\"]\n",
    "    conv2_lrs = [0.0005, 0.001]\n",
    "    conv2_batch_sizes = [256, 512]\n",
    "\n",
    "    for arch in conv2d_archs:\n",
    "        for opt in conv2_optimizers:\n",
    "            for lr in conv2_lrs:\n",
    "                for bs in conv2_batch_sizes:\n",
    "                    label = f\"{arch['name']}_{opt}_lr{lr}_bs{bs}\"\n",
    "                    experiments.append({\n",
    "                        \"label\": label,\n",
    "                        \"family\": arch[\"family\"],\n",
    "                        \"model_builder\": arch[\"builder\"],\n",
    "                        \"model_kwargs\": arch[\"kwargs\"],\n",
    "                        \"optimizer\": opt,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"batch_size\": bs,\n",
    "                    })\n",
    "\n",
    " \n",
    "    dense_archs = [\n",
    "        # DENSE4\n",
    "        {\n",
    "            \"name\": \"dense4_small\",\n",
    "            \"family\": \"dense4\",\n",
    "            \"builder\": build_dense4_model,\n",
    "            \"kwargs\": dict(\n",
    "                units1=128, units2=64, units3=32, units4=16,\n",
    "                dropout1=0.3, dropout2=0.3, dropout3=0.2,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dense4_big\",\n",
    "            \"family\": \"dense4\",\n",
    "            \"builder\": build_dense4_model,\n",
    "            \"kwargs\": dict(\n",
    "                units1=256, units2=128, units3=64, units4=32,\n",
    "                dropout1=0.3, dropout2=0.3, dropout3=0.2,\n",
    "            ),\n",
    "        },\n",
    "        # DENSE5\n",
    "        {\n",
    "            \"name\": \"dense5_small\",\n",
    "            \"family\": \"dense5\",\n",
    "            \"builder\": build_dense5_model,\n",
    "            \"kwargs\": dict(\n",
    "                units1=256, units2=192, units3=128, units4=64, units5=32,\n",
    "                dropout1=0.3, dropout2=0.3, dropout3=0.2, dropout4=0.2,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dense5_big\",\n",
    "            \"family\": \"dense5\",\n",
    "            \"builder\": build_dense5_model,\n",
    "            \"kwargs\": dict(\n",
    "                units1=384, units2=256, units3=192, units4=96, units5=48,\n",
    "                dropout1=0.3, dropout2=0.3, dropout3=0.2, dropout4=0.2,\n",
    "            ),\n",
    "        },\n",
    "        # DENSE6\n",
    "        {\n",
    "            \"name\": \"dense6_small\",\n",
    "            \"family\": \"dense6\",\n",
    "            \"builder\": build_dense6_model,\n",
    "            \"kwargs\": dict(\n",
    "                units1=256, units2=192, units3=128, units4=96, units5=64, units6=32,\n",
    "                dropout1=0.3, dropout2=0.3, dropout3=0.3, dropout4=0.2, dropout5=0.2,\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dense6_big\",\n",
    "            \"family\": \"dense6\",\n",
    "            \"builder\": build_dense6_model,\n",
    "            \"kwargs\": dict(\n",
    "                units1=384, units2=256, units3=192, units4=128, units5=64, units6=32,\n",
    "                dropout1=0.3, dropout2=0.3, dropout3=0.3, dropout4=0.2, dropout5=0.2,\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    dense_optimizers = [\"adam\", \"rmsprop\"]\n",
    "    dense_lrs = [0.001]\n",
    "    dense_batch_sizes = [256, 512]\n",
    "\n",
    "    for arch in dense_archs:\n",
    "        for opt in dense_optimizers:\n",
    "            for lr in dense_lrs:\n",
    "                for bs in dense_batch_sizes:\n",
    "                    label = f\"{arch['name']}_{opt}_lr{lr}_bs{bs}\"\n",
    "                    experiments.append({\n",
    "                        \"label\": label,\n",
    "                        \"family\": arch[\"family\"],\n",
    "                        \"model_builder\": arch[\"builder\"],\n",
    "                        \"model_kwargs\": arch[\"kwargs\"],\n",
    "                        \"optimizer\": opt,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"batch_size\": bs,\n",
    "                    })\n",
    "\n",
    "    print(f\"Generated {len(experiments)} experiments.\")\n",
    "    return experiments\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "140cef59",
   "metadata": {},
   "source": [
    "some helpers and plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "da271ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:01.080869Z",
     "start_time": "2025-11-13T20:19:01.077824Z"
    }
   },
   "source": [
    "def select_top_by_family(results, family, metric=\"best_val_mae\", top_n=3):\n",
    "    family_results = [r for r in results if r[\"family\"] == family]\n",
    "    family_results_sorted = sorted(family_results, key=lambda r: r[metric])\n",
    "    return family_results_sorted[:top_n]\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "484b3dd3",
   "metadata": {},
   "source": [
    "plotting everything per fammily"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd19f856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:01.128973Z",
     "start_time": "2025-11-13T20:19:01.125301Z"
    }
   },
   "source": [
    "def plot_family_histories(results, family, metric=\"mae\", top_n=5):\n",
    "    top_results = select_top_by_family(results, family, metric=\"best_val_mae\", top_n=top_n)\n",
    "\n",
    "    if not top_results:\n",
    "        print(f\"No results for family={family}\")\n",
    "        return\n",
    "\n",
    "    plt.figure()\n",
    "    for r in top_results:\n",
    "        h = r[\"history\"]\n",
    "        label = r[\"label\"]\n",
    "        if metric in h:\n",
    "            plt.plot(h[metric], linestyle=\"-\", alpha=0.7, label=f\"{label} (train)\")\n",
    "        val_key = f\"val_{metric}\"\n",
    "        if val_key in h:\n",
    "            plt.plot(h[val_key], linestyle=\"--\", alpha=0.7, label=f\"{label} (val)\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{family} – top {top_n} by val MAE ({metric} per epoch)\")\n",
    "    plt.legend(fontsize=7)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "d1a36748",
   "metadata": {},
   "source": [
    "best inter familly"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6c0339b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:01.177974Z",
     "start_time": "2025-11-13T20:19:01.173585Z"
    }
   },
   "source": [
    "def plot_best_overall(results, metric=\"mae\"):\n",
    "    best_per_family = []\n",
    "    families = sorted(set(r[\"family\"] for r in results))\n",
    "    for fam in families:\n",
    "        top = select_top_by_family(results, fam, metric=\"best_val_mae\", top_n=1)\n",
    "        if top:\n",
    "            best_per_family.append(top[0])\n",
    "\n",
    "    if not best_per_family:\n",
    "        print(\"No results to plot in best_overall.\")\n",
    "        return\n",
    "\n",
    "    plt.figure()\n",
    "    for r in best_per_family:\n",
    "        h = r[\"history\"]\n",
    "        label = f\"{r['family']} | {r['label']}\"\n",
    "        val_key = f\"val_{metric}\"\n",
    "        if val_key in h:\n",
    "            plt.plot(h[val_key], linestyle=\"-\", label=label)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"Best model per family – validation {metric}\")\n",
    "    plt.legend(fontsize=7)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "900a5841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:19:01.226036Z",
     "start_time": "2025-11-13T20:19:01.221635Z"
    }
   },
   "source": [
    "def run_experiments(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    experiments = generate_experiments()\n",
    "    print(f\"Running {len(experiments)} experiments...\\n\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, exp in enumerate(experiments):\n",
    "        print(f\"\\n=== Experiment {i+1}/{len(experiments)}: {exp['label']} ===\")\n",
    "        res = train_single_experiment(\n",
    "            model_builder=exp[\"model_builder\"],\n",
    "            model_kwargs=exp[\"model_kwargs\"],\n",
    "            optimizer_name=exp[\"optimizer\"],\n",
    "            learning_rate=exp[\"learning_rate\"],\n",
    "            batch_size=exp[\"batch_size\"],\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_val=X_val, y_val=y_val,\n",
    "            X_test=X_test, y_test=y_test,\n",
    "            label=exp[\"label\"],\n",
    "            family=exp[\"family\"],\n",
    "        )\n",
    "        results.append(res)\n",
    "\n",
    "    # DataFrame overzicht\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            \"label\": r[\"label\"],\n",
    "            \"family\": r[\"family\"],\n",
    "            \"optimizer\": r[\"optimizer\"],\n",
    "            \"lr\": r[\"learning_rate\"],\n",
    "            \"batch_size\": r[\"batch_size\"],\n",
    "            \"best_val_loss\": r[\"best_val_loss\"],\n",
    "            \"best_val_mae\": r[\"best_val_mae\"],\n",
    "            \"test_loss\": r[\"test_loss\"],\n",
    "            \"test_mae\": r[\"test_mae\"],\n",
    "        }\n",
    "        for r in results\n",
    "    ])\n",
    "\n",
    "    print(\"\\n==================== RESULT TABLE (sorted by test MAE) ====================\")\n",
    "    print(df.sort_values(\"test_mae\").head(20))\n",
    "\n",
    "    # 1) conv1d verschillen\n",
    "    plot_family_histories(results, family=\"conv1d\", metric=\"mae\", top_n=5)\n",
    "\n",
    "    # 2) conv2d verschillen\n",
    "    plot_family_histories(results, family=\"conv2d\", metric=\"mae\", top_n=5)\n",
    "\n",
    "    # 3) dense4 / dense5 / dense6 verschillen\n",
    "    plot_family_histories(results, family=\"dense4\", metric=\"mae\", top_n=5)\n",
    "    plot_family_histories(results, family=\"dense5\", metric=\"mae\", top_n=5)\n",
    "    plot_family_histories(results, family=\"dense6\", metric=\"mae\", top_n=5)\n",
    "\n",
    "    # 4) beste per family tegen elkaar\n",
    "    plot_best_overall(results, metric=\"mae\")\n",
    "\n",
    "    return results, df\n"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "8cc4e1f7ea26382a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-13T20:19:01.269152Z"
    }
   },
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "boards, scores = build_dataset(DATASET_PATH)\n",
    "\n",
    "# ---- Train / Val / Test split ----\n",
    "N = len(boards)\n",
    "test_size = int(N * 0.2)\n",
    "val_size  = int((N - test_size) * 0.2)\n",
    "\n",
    "X_test = boards[:test_size]\n",
    "y_test = scores[:test_size]\n",
    "\n",
    "X_trainval = boards[test_size:]\n",
    "y_trainval = scores[test_size:]\n",
    "\n",
    "X_val = X_trainval[:val_size]\n",
    "y_val = y_trainval[:val_size]\n",
    "\n",
    "X_train = X_trainval[val_size:]\n",
    "y_train = y_trainval[val_size:]\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Val size:   {len(X_val)}\")\n",
    "print(f\"Test size:  {len(X_test)}\")\n",
    "\n",
    "# hyperparameter search\n",
    "results, df = run_experiments(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "# eventueel: beste config tonen\n",
    "best_row = df.sort_values(\"test_mae\").iloc[0]\n",
    "print(\"\\nBest experiment based on test MAE:\")\n",
    "print(best_row)\n",
    "\n",
    "print(df)\n",
    "print (results)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Loading dataset...\n",
      "Processing 12000 games\n",
      "Processed game 0/12000\n",
      "Processed game 1000/12000\n",
      "Processed game 2000/12000\n",
      "Processed game 3000/12000\n",
      "Processed game 4000/12000\n",
      "Processed game 5000/12000\n",
      "Processed game 6000/12000\n",
      "Processed game 7000/12000\n",
      "Processed game 8000/12000\n",
      "Processed game 9000/12000\n",
      "Processed game 10000/12000\n",
      "Processed game 11000/12000\n",
      "Train size: 581664\n",
      "Val size:   145415\n",
      "Test size:  181769\n",
      "Generated 76 experiments.\n",
      "Running 76 experiments...\n",
      "\n",
      "\n",
      "=== Experiment 1/76: conv1d_small_adam_lr0.0005_bs256 ===\n",
      "\n",
      "==== Running experiment: conv1d_small_adam_lr0.0005_bs256 (conv1d) ====\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39c9ab3029123e6f",
   "metadata": {},
   "source": [
    "Als train <<< val → overfitting\n",
    "Als train ≈ val → goed model\n",
    "Als train ≈ hoog en val ook hoog → underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336aa070fa00cd3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
